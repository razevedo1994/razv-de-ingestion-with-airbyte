version: "3"
# ====================================== AIRFLOW ENVIRONMENT VARIABLES =======================================
x-environment:
  &airflow_environment
  - AIRFLOW__CORE__EXECUTOR=LocalExecutor
  - AIRFLOW__CORE__LOAD_DEFAULT_CONNECTIONS=False
  - AIRFLOW__CORE__LOAD_EXAMPLES=False
  - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql://airflow:airflow@postgres:5432/airflow
  - AIRFLOW__CORE__STORE_DAG_CODE=True
  - AIRFLOW__CORE__STORE_SERIALIZED_DAGS=True
  - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True
  - AIRFLOW__WEBSERVER__RBAC=False
x-airflow-image: &airflow_image apache/airflow:2.3.4-python3.10
# ====================================== /AIRFLOW ENVIRONMENT VARIABLES ======================================
services:

  postgres:
    image: postgres:12-alpine
    container_name: postgres
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    ports:
      - "5432:5432"
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD", "pg_isready", "-U", "airflow" ]
      interval: 5s
      retries: 5

  init:
    build: ./docker-images/airflow
    image: airflow:2.3.4
    container_name: airflow-init
    depends_on:
      - postgres
    environment: *airflow_environment
    entrypoint: /bin/bash
    command: -c 'airflow db upgrade && sleep 5 && airflow users create --username admin --password admin --firstname Anonymous --lastname Admin --role Admin --email admin@example.org'

  webserver:
    build: ./docker-images/airflow
    image: airflow:2.3.4
    container_name: airflow-webserver
    restart: always
    depends_on:
      - postgres
    ports:
      - "8080:8080"
    volumes:
      - logs:/opt/airflow/logs
    healthcheck:
      test:
        [
          "CMD",
          "curl",
          "--fail",
          "http://localhost:8080/health"
        ]
      interval: 10s
      timeout: 10s
      retries: 5
    environment: *airflow_environment
    command: webserver

  scheduler:
    build: ./docker-images/airflow
    image: airflow:2.3.4
    container_name: aiflow-scheduler
    restart: always
    depends_on:
      - postgres
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - logs:/opt/airflow/logs
    healthcheck:
      test:
        [
          "CMD-SHELL",
          'airflow jobs check --job-type SchedulerJob --hostname "$${HOSTNAME}"'
        ]
      interval: 10s
      timeout: 10s
      retries: 5
    environment: *airflow_environment
    command: scheduler

volumes:
  logs:
  postgres-db-volume:


networks:
  default:
    name: default_network
